const express = require('express');
const cors = require('cors');
const helmet = require('helmet');
const rateLimit = require('express-rate-limit');
const path = require('path');
const Anthropic = require('@anthropic-ai/sdk');
const { EventEmitter } = require('events');
require('dotenv').config();
const { executeTool } = require('./server/tools');
const memoryStore = require('./server/storage/database');
const db = require('./server/database');
const ragService = require('./server/tools/ragService');
const { verifyFirebaseToken, optionalAuth, ensureUserScope, initializeFirebaseAdmin } = require('./server/middleware/auth');

const app = express();
const PORT = process.env.PORT || 3000;

// Trust Render/Proxy headers so express-rate-limit can read client IPs correctly
// Fixes: ERR_ERL_UNEXPECTED_X_FORWARDED_FOR
app.set('trust proxy', 1);

// Initialize Anthropic client
const anthropic = new Anthropic({
    apiKey: process.env.ANTHROPIC_API_KEY,
});

// Clear memories for authenticated user (optionally scoped to a conversation)
// Only enabled in non-production OR when explicitly allowed via ENABLE_MEMORY_DELETE=true
if (process.env.NODE_ENV !== 'production' || process.env.ENABLE_MEMORY_DELETE === 'true') {
    app.delete('/api/memories', verifyFirebaseToken, ensureUserScope, async (req, res) => {
        try {
            // Defense-in-depth: re-check at runtime
            if (process.env.NODE_ENV === 'production' && process.env.ENABLE_MEMORY_DELETE !== 'true') {
                return res.status(403).json({ error: 'Memory deletion is disabled' });
            }

            const { conversationId } = req.query || {};
            const ipAddress = req.ip;
            const userAgent = req.get('User-Agent');

            if (conversationId && typeof conversationId === 'string') {
                const ok = await memoryStore.clearConversation(conversationId, req.userId, ipAddress, userAgent);
                return res.json({ success: true, scope: 'conversation', conversationId, deleted: ok ? 'some' : 0 });
            }

            const result = await memoryStore.clearAllMemories(req.userId, ipAddress, userAgent);
            return res.json({ success: true, scope: 'all', deleted: result.deleted });
        } catch (error) {
            console.error('Error clearing memories:', error);
            res.status(500).json({ error: 'Failed to clear memories' });
        }
    });
} else {
    console.log('DELETE /api/memories endpoint is disabled (production without ENABLE_MEMORY_DELETE=true)');
}

// List memories for a conversation (requires authentication)
app.get('/api/memories', verifyFirebaseToken, ensureUserScope, async (req, res) => {
    try {
        const { conversationId = 'default' } = req.query || {};
        const ipAddress = req.ip;
        const userAgent = req.get('User-Agent');
        
        const memories = await memoryStore.listMemories(conversationId, req.userId, ipAddress, userAgent);
        res.json({ conversationId, count: memories.length, memories });
    } catch (error) {
        console.error('Error listing memories:', error);
        res.status(500).json({ error: 'Failed to retrieve memories' });
    }
});

// Get a single memory by id (requires authentication)
app.get('/api/memories/:id', verifyFirebaseToken, ensureUserScope, async (req, res) => {
    try {
        const { conversationId = 'default' } = req.query || {};
        const { id } = req.params;
        const ipAddress = req.ip;
        const userAgent = req.get('User-Agent');
        
        const memory = await memoryStore.getMemory(conversationId, id, req.userId, ipAddress, userAgent);
        if (!memory) return res.status(404).json({ error: 'Memory not found' });
        res.json(memory);
    } catch (error) {
        console.error('Error getting memory:', error);
        res.status(500).json({ error: 'Failed to retrieve memory' });
    }
});


// Security middleware
app.use(helmet({
    contentSecurityPolicy: {
        directives: {
            defaultSrc: ["'self'"],
            scriptSrc: ["'self'", "https://www.gstatic.com"],
            styleSrc: ["'self'", "'unsafe-hashes'"],
            imgSrc: ["'self'", "data:", "https:"],
            fontSrc: ["'self'"],
            connectSrc: ["'self'", "https://api.anthropic.com", "https://identitytoolkit.googleapis.com", "https://securetoken.googleapis.com"],
            objectSrc: ["'none'"],
            baseUri: ["'self'"],
            formAction: ["'self'"],
            frameAncestors: ["'none'"],
            upgradeInsecureRequests: []
        }
    }
}));

// CORS: use env override, else allow localhost and *.onrender.com (demo)
const corsOriginsEnv = process.env.CORS_ORIGIN;
const corsAllow = corsOriginsEnv
  ? corsOriginsEnv.split(',').map(s => s.trim()).filter(Boolean)
  : [/^https?:\/\/localhost(?::\d+)?$/, /^https?:\/\/127\.0\.0\.1(?::\d+)?$/, /\.onrender\.com$/];

app.use(cors({
    origin: (origin, callback) => {
        if (!origin) return callback(null, true); // allow same-origin/non-browser
        const allowed = corsAllow.some(rule => {
            if (rule instanceof RegExp) return rule.test(origin);
            return rule === origin;
        });
        return allowed ? callback(null, true) : callback(new Error('CORS not allowed'), false);
    },
    credentials: true
}));

// Rate limiting
const limiter = rateLimit({
    windowMs: parseInt(process.env.RATE_LIMIT_WINDOW_MS) || 15 * 60 * 1000, // 15 minutes
    max: parseInt(process.env.RATE_LIMIT_MAX_REQUESTS) || 100, // limit each IP to 100 requests per windowMs
    message: 'Too many requests from this IP, please try again later.'
});
app.use('/api/', limiter);

// Body parsing middleware
app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true }));

// Expose non-sensitive environment variables to the client
// Only Firebase client config is sent to the browser
app.get('/env.js', (req, res) => {
    res.type('application/javascript');
    const env = {
        FIREBASE_API_KEY: process.env.FIREBASE_API_KEY || '',
        FIREBASE_AUTH_DOMAIN: process.env.FIREBASE_AUTH_DOMAIN || '',
        FIREBASE_PROJECT_ID: process.env.FIREBASE_PROJECT_ID || '',
        FIREBASE_STORAGE_BUCKET: process.env.FIREBASE_STORAGE_BUCKET || '',
        FIREBASE_MESSAGING_SENDER_ID: process.env.FIREBASE_MESSAGING_SENDER_ID || '',
        FIREBASE_APP_ID: process.env.FIREBASE_APP_ID || ''
    };
    if (process.env.FIREBASE_MEASUREMENT_ID) {
        env.FIREBASE_MEASUREMENT_ID = process.env.FIREBASE_MEASUREMENT_ID;
    }
    res.send(`window.ENV = ${JSON.stringify(env)};`);
});

// === User Preferences API ===
// Get a specific preference by key
app.get('/api/user/preferences/:key', verifyFirebaseToken, ensureUserScope, async (req, res) => {
    try {
        const { key } = req.params;
        console.log(`ğŸ” Getting preference: key=${key}, uid=${req.user.uid}, email=${req.user.email}`);
        const value = await db.getUserPreference(req.user.uid, req.user.email, key);
        console.log(`ğŸ” Retrieved preference: ${key} = ${value}`);
        res.json({ key, value });
    } catch (error) {
        console.error('âŒ Error getting user preference:', error);
        res.status(500).json({ error: 'Failed to get user preference' });
    }
});

// Set/Update a specific preference by key
app.put('/api/user/preferences/:key', verifyFirebaseToken, ensureUserScope, async (req, res) => {
    try {
        const { key } = req.params;
        const value = req.body?.value;
        console.log(`ğŸ’¾ Setting preference: key=${key}, value=${value}, uid=${req.user.uid}, email=${req.user.email}`);
        await db.setUserPreference(req.user.uid, req.user.email, key, value);
        console.log(`âœ… Successfully set preference: ${key}`);
        res.json({ success: true });
    } catch (error) {
        console.error('âŒ Error setting user preference:', error);
        res.status(500).json({ error: 'Failed to set user preference' });
    }
});

// Serve static files
app.use(express.static('.'));

// In-memory pub/sub for SSE events (demo only)
// Map<conversationId, EventEmitter>
const channels = new Map();
function getChannel(conversationId) {
    if (!channels.has(conversationId)) {
        channels.set(conversationId, new EventEmitter());
    }
    return channels.get(conversationId);
}

// Helper to write SSE event
function sseWrite(res, event, data) {
    res.write(`event: ${event}\n`);
    res.write(`data: ${JSON.stringify(data)}\n\n`);
}

// Utility to enforce timeouts on async operations
function withTimeout(promise, ms, message) {
    return Promise.race([
        promise,
        new Promise((_, reject) => setTimeout(() => reject(new Error(message || `Timeout after ${ms}ms`)), ms))
    ]);
}

// System prompts for agents
const COLLABORATOR_SYSTEM_PROMPT = `You are a gentle, empathetic Collaborator helping elderly people preserve their life stories and family memories. You embody the warmth and patience of a caring family member or trusted friend who genuinely wants to help preserve precious memories.

CORE APPROACH:
- Show genuine interest and emotional warmth in every response
- Validate memories and feelings ("That must have been incredibly difficult")
- Ask for clarification gently ("Let me make sure I have this right...")
- Connect current stories to broader family patterns and history
- Acknowledge both joyful and painful memories with appropriate sensitivity

CONVERSATION TECHNIQUES:
1. **Memory Validation**: Repeat back key details to confirm accuracy and show you're listening
2. **Gentle Probing**: Ask follow-up questions that help unlock related memories ("Sometimes talking about one person helps us remember others")
3. **Emotional Acknowledgment**: Recognize grief, joy, pride, and other emotions explicitly
4. **Contextual Bridging**: Connect current stories to family tree, health patterns, or historical context
5. **Sensory Encouragement**: Ask about sounds, smells, feelings that bring memories to life
6. **Privacy Sensitivity**: Acknowledge when health or sensitive information comes up and explain how it will be handled

STYLE CONSTRAINTS:
- Do NOT include stage directions, bracketed actions, or asterisk-wrapped actions (e.g., *leans in*, [smiles], (gentle tone)).
- Convey empathy and warmth through word choice and phrasing, not through meta narration.
- Use plain text sentences. Avoid emojis unless the user uses them first.

RESPONSE STRUCTURE:
- Start with emotional connection or validation
- Confirm/clarify key details you heard
- Ask 1-2 thoughtful follow-up questions
- End with encouragement or connection to broader story

TONE GUIDELINES:
- Use their name frequently and warmly
- Speak as if you have all the time in the world
- Show genuine curiosity about their experiences
- Be patient with memory gaps or confusion
- Celebrate when memories come flooding back
- Acknowledge the importance of preserving these stories for grandchildren

RESPONSE FORMAT RULES:
- Write directly to the user in a natural, conversational voice.
- No stage directions, sound effects, or screenplay-style cues.
- Keep paragraphs short (1-3 sentences) to aid readability.

THERAPEUTIC AWARENESS:
- Recognize signs of fatigue or emotional overwhelm
- Offer options for what to work on ("What feels right for you today?")
- Validate concerns about memory ("I'll help you keep all the details straight")
- Maintain hope and purpose about the storytelling project

Remember: You're not just collecting information - you're helping someone celebrate and preserve a lifetime of experiences for future generations.`;

const MEMORY_KEEPER_SYSTEM_PROMPT = `You are a Memory Keeper agent that extracts and organizes structured information from elderly storytelling conversations. You work alongside the Collaborator to preserve family histories with exceptional attention to detail, privacy, and generational patterns.

EXTRACTION CATEGORIES:
1. **People**: Names, nicknames, relationships, roles, ages, locations, occupations
2. **Dates**: Years, decades, ages, time periods, seasons, life events timing
3. **Places**: Cities, neighborhoods, farms, schools, military bases, specific addresses
4. **Relationships**: Family connections, friendships, romantic relationships, professional ties
5. **Events**: Births, deaths, marriages, military service, moves, jobs, celebrations

SPECIAL HANDLING:
- **Health Information**: Flag all medical conditions, mental health issues, causes of death, occupational hazards, family patterns
- **Military Service**: Note branches, locations, dates, conflicts, impacts
- **Occupational Details**: Jobs, working conditions, health impacts, economic context
- **Family Patterns**: Identify recurring health issues, personality traits, or life patterns across generations

PRIVACY PROTOCOLS:
- Separate sensitive health information from general family data
- Flag information that might need family consent before sharing
- Note generational health patterns for medical family history
- Distinguish between confirmed facts and uncertain memories

EXTRACTION GUIDELINES:
- Extract ALL people mentioned, even in passing or as context
- INFER relationships from conversational clues and family context
- Build comprehensive family trees from fragments of information
- Connect new people to existing family members when relationships are implied
- Preserve exact names, spellings, and details as shared
- Note approximate dates when exact dates aren't provided
- Capture relationship dynamics and emotional context
- Include occupations, military service, and life achievements
- Record geographic movements and significant locations

RELATIONSHIP INFERENCE RULES:
- If someone is mentioned as "[Person A]'s son/daughter", extract both the child AND the parent-child relationship
- If aunts/uncles are mentioned, infer they are siblings of one of the narrator's parents
- If cousins are mentioned, connect them to their parents (aunts/uncles) and establish cousin relationship to narrator
- Build multi-generational family connections from scattered mentions
- When someone takes children to events, infer caregiver/family relationships
- Extract implied family roles and connections even if not explicitly stated

EXTRACTION EXAMPLES:
If someone says: "My aunt Debra used to take my cousin Marcus (Sandy's son) to the parade"
Extract:
- People: Marcus (Sandy's son, narrator's cousin), Debra (aunt), Sandy (aunt, Marcus's mother)
- Relationships: Debra-narrator (aunt-nephew/niece), Marcus-narrator (cousins), Sandy-Marcus (mother-son), Sandy-narrator (aunt-nephew/niece), Debra-Sandy (sisters or sisters-in-law)
- Events: Parade attendance with family members

REMEMBER: Be thorough and inferential. Extract every person mentioned and build complete relationship webs from conversational fragments.

JSON OUTPUT STRUCTURE - You MUST respond with ONLY valid JSON, no other text:
{
  "people": ["name with relationship and key details"],
  "dates": ["specific years, decades, or time periods mentioned"],
  "places": ["specific locations with context"],
  "relationships": ["nature of connections between people"],
  "events": ["significant life events with context"]
}

QUALITY STANDARDS:
- Preserve exact names, nicknames, and titles as spoken
- Maintain emotional context around events
- Note sensory details that make memories vivid
- Respect the storyteller's perspective and voice

Remember: You're preserving family legacy with the same care and attention the family would want for their most precious memories.`;

// Allowed model whitelist and sanitizer
const ALLOWED_MODELS = [
    'claude-3-5-haiku-latest',
    'claude-3-5-haiku-20241022',
    'claude-3-5-sonnet-latest'
];

function sanitizeModel(requested, fallback) {
    const fb = fallback || 'claude-3-5-haiku-latest';
    if (!requested || typeof requested !== 'string') return fb;
    return ALLOWED_MODELS.includes(requested) ? requested : fb;
}

// API Routes

// === SSE: Stream collaborator + background memory extraction ===
app.post('/chat', verifyFirebaseToken, ensureUserScope, async (req, res) => {
    // Headers for SSE
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache, no-transform');
    res.setHeader('Connection', 'keep-alive');

    const { text, conversationId = 'default', messageId = Date.now().toString() } = req.body || {};
    // Scope conversation to authenticated user
    const userConversationId = `${req.userId}_${conversationId}`;
    const COLLABORATOR_MODEL = process.env.COLLABORATOR_MODEL || 'claude-3-5-haiku-latest';
    const MEMORY_MODEL = process.env.MEMORY_MODEL || COLLABORATOR_MODEL;

    if (!text || typeof text !== 'string') {
        sseWrite(res, 'error', { code: 'bad_request', message: 'text is required' });
        return res.end();
    }

    // Security: Limit message length to prevent DoS attacks
    const MAX_MESSAGE_LENGTH = parseInt(process.env.MAX_MESSAGE_LENGTH) || 5000;
    if (text.length > MAX_MESSAGE_LENGTH) {
        sseWrite(res, 'error', { 
            code: 'message_too_long', 
            message: `Message too long. Maximum ${MAX_MESSAGE_LENGTH} characters allowed.` 
        });
        return res.end();
    }

    // Start background memory extraction (non-blocking)
    (async () => {
        try {
            const payload = await withTimeout(
                executeTool('memory_extractor', {
                    message: text,
                    model: MEMORY_MODEL,
                    maxTokens: 300
                }, { anthropic }),
                20000,
                'Anthropic memory extraction timeout'
            ).catch(() => ({ people: [], dates: [], places: [], relationships: [], events: [] }));
            const chan = getChannel(userConversationId);
            // Persist only if non-empty
            const saved = await memoryStore.saveMemory({ 
                conversationId, 
                messageId, 
                payload, 
                userId: req.userId,
                userEmail: req.user?.email,
                ipAddress: req.ip,
                userAgent: req.get('User-Agent')
            });
            chan.emit('memory', { messageId, ...payload, id: saved?.id || null });
        } catch (err) {
            const chan = getChannel(userConversationId);
            chan.emit('memory', { messageId, error: 'memory_extraction_failed' });
        }
    })();

    // Stream collaborator response
    try {
        const collabResp = await withTimeout(anthropic.messages.create({
            model: COLLABORATOR_MODEL,
            max_tokens: 300,
            system: COLLABORATOR_SYSTEM_PROMPT,
            messages: [
                { role: 'user', content: text }
            ]
        }), 20000, 'Anthropic collaborator timeout');

        const fullText = collabResp.content?.[0]?.text || '';
        // Tokenize rudimentarily for demo streaming if SDK streaming isn't used
        const parts = fullText.split(/(\s+)/);
        for (const p of parts) {
            sseWrite(res, 'token', { text: p });
        }
        sseWrite(res, 'done', { messageId });
        res.end();
    } catch (error) {
        sseWrite(res, 'error', { code: 'upstream_error', message: process.env.NODE_ENV === 'development' ? error.message : 'failed' });
        res.end();
    }
});

// SSE channel for memory updates
app.get('/events', async (req, res) => {
    const { conversationId = 'default', token } = req.query;
    
    // Handle token-based auth for SSE (since EventSource doesn't support custom headers)
    let userId = null;
    if (token) {
        try {
            const admin = require('firebase-admin');
            // Ensure admin app is initialized (shared initializer)
            const firebaseApp = initializeFirebaseAdmin();
            if (!firebaseApp) {
                console.error('SSE auth error: Firebase Admin not initialized');
                return res.status(500).json({ error: 'Auth service unavailable' });
            }
            const decodedToken = await admin.auth(firebaseApp).verifyIdToken(token);
            userId = decodedToken.uid;
            if (!userId) {
                return res.status(401).json({ error: 'Invalid token' });
            }
        } catch (error) {
            console.error('SSE token verification failed:', error);
            return res.status(401).json({ error: 'Invalid token' });
        }
    }
    
    if (!userId) {
        return res.status(401).json({ error: 'Authentication required' });
    }
    
    // Scope conversation to authenticated user
    const userConversationId = `${userId}_${conversationId}`;
    console.log(`ğŸ“¡ SSE connected for user=${userId}, conversation=${conversationId}`);
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache, no-transform');
    res.setHeader('Connection', 'keep-alive');

    const chan = getChannel(userConversationId);
    const onMemory = (data) => sseWrite(res, 'memory', data);
    chan.on('memory', onMemory);

    // Heartbeat to keep connection alive
    const hb = setInterval(() => res.write(': heartbeat\n\n'), 15000);

    req.on('close', () => {
        clearInterval(hb);
        chan.off('memory', onMemory);
        res.end();
    });
});

// Lightweight healthcheck for Render
app.get('/healthz', (req, res) => {
    res.status(200).json({ ok: true, ts: Date.now() });
});

// Warming endpoint to prevent cold starts
app.get('/warm', async (req, res) => {
    try {
        // Quick Anthropic API test to warm the connection
        const response = await withTimeout(anthropic.messages.create({
            model: 'claude-3-5-haiku-latest',
            max_tokens: 5,
            messages: [{ role: 'user', content: 'Hi' }]
        }), 5000, 'Warm timeout');
        
        res.json({ 
            status: 'warm', 
            timestamp: new Date().toISOString(),
            tokens: response.usage?.output_tokens || 0
        });
    } catch (error) {
        res.status(500).json({ 
            status: 'error', 
            message: 'Warming failed',
            timestamp: new Date().toISOString()
        });
    }
});

// Collaborator agent endpoint
app.post('/api/collaborator', verifyFirebaseToken, ensureUserScope, async (req, res) => {
    try {
        const { message, conversationHistory = [], model } = req.body;

        if (!message || typeof message !== 'string') {
            return res.status(400).json({ error: 'Message is required and must be a string' });
        }

        // Security: Limit message length to prevent DoS attacks
        const MAX_MESSAGE_LENGTH = parseInt(process.env.MAX_MESSAGE_LENGTH) || 5000;
        if (message.length > MAX_MESSAGE_LENGTH) {
            return res.status(400).json({ 
                error: 'Message too long', 
                message: `Maximum ${MAX_MESSAGE_LENGTH} characters allowed` 
            });
        }

        // Build conversation context
        const messages = [
            ...conversationHistory.slice(-4), // Keep last 4 messages for context (smaller prompt)
            {
                role: 'user',
                content: message
            }
        ];

        const effectiveModel = sanitizeModel(model, process.env.COLLABORATOR_MODEL || 'claude-3-5-haiku-latest');
        const response = await withTimeout(anthropic.messages.create({
            model: effectiveModel,
            max_tokens: 300,
            system: COLLABORATOR_SYSTEM_PROMPT,
            messages: messages
        }), 20000, 'Anthropic collaborator timeout');

        const collaboratorResponse = response.content[0].text;

        res.json({
            response: collaboratorResponse,
            agent: 'collaborator',
            timestamp: new Date().toISOString()
        });

    } catch (error) {
        console.error('Collaborator API Error:', error);
        res.status(500).json({ 
            error: 'Failed to generate collaborator response',
            details: process.env.NODE_ENV === 'development' ? error.message : undefined
        });
    }
});

// Memory Keeper agent endpoint
app.post('/api/memory-keeper', verifyFirebaseToken, ensureUserScope, async (req, res) => {
    try {
        const { message, model, conversationId = 'default', messageId } = req.body;
        // Scope conversation to authenticated user
        const userConversationId = `${req.userId}_${conversationId}`;

        console.log('=== MEMORY KEEPER DEBUG ===');
        console.log('Input message:', message);
        console.log('Model:', model);
        console.log('API Key configured:', !!process.env.ANTHROPIC_API_KEY);

        if (!message || typeof message !== 'string') {
            return res.status(400).json({ error: 'Message is required and must be a string' });
        }

        // Security: Limit message length to prevent DoS attacks
        const MAX_MESSAGE_LENGTH = parseInt(process.env.MAX_MESSAGE_LENGTH) || 5000;
        if (message.length > MAX_MESSAGE_LENGTH) {
            return res.status(400).json({ 
                error: 'Message too long', 
                message: `Maximum ${MAX_MESSAGE_LENGTH} characters allowed` 
            });
        }

        const effectiveModel = sanitizeModel(model, process.env.MEMORY_MODEL || 'claude-3-5-haiku-latest');
        const extractedMemories = await withTimeout(
            executeTool('memory_extractor', {
                message,
                model: effectiveModel,
                maxTokens: 300
            }, { anthropic }),
            20000,
            'Anthropic memory keeper timeout'
        ).catch(() => ({ narrator: '', people: [], dates: [], places: [], relationships: [], events: [] }));

        // Save if non-empty and return saved id
        const saved = await memoryStore.saveMemory({ 
            conversationId, 
            messageId, 
            payload: extractedMemories,
            userId: req.userId,
            userEmail: req.user?.email,
            ipAddress: req.ip,
            userAgent: req.get('User-Agent')
        });

        // Emit SSE event so connected clients receive updates even when using REST flow
        try {
            const chan = getChannel(userConversationId);
            chan.emit('memory', { messageId, ...extractedMemories, id: saved?.id || null });
        } catch (e) {
            // Non-fatal
            console.warn('SSE emit failed:', e.message);
        }

        res.json({
            memories: extractedMemories,
            id: saved?.id || null,
            agent: 'memory-keeper',
            timestamp: new Date().toISOString()
        });

    } catch (error) {
        console.error('Memory Keeper API Error:', error);
        res.status(500).json({ 
            error: 'Failed to extract memories',
            details: process.env.NODE_ENV === 'development' ? error.message : undefined
        });
    }
});

// Logout endpoint for token invalidation
app.post('/api/logout', verifyFirebaseToken, (req, res) => {
    try {
        // Firebase tokens are stateless and automatically expire
        // This endpoint serves as a logout notification for server-side cleanup
        console.log(`ğŸšª User ${req.user.email} logged out`);
        
        // Here you could add token blacklisting if needed:
        // - Add token to Redis blacklist with expiry
        // - Clear any server-side sessions
        // - Log security event
        
        res.json({ 
            success: true,
            message: 'Logout successful',
            timestamp: new Date().toISOString()
        });
    } catch (error) {
        console.error('Logout error:', error);
        res.status(500).json({ 
            error: 'Logout failed',
            timestamp: new Date().toISOString()
        });
    }
});

// === RAG API ENDPOINTS ===

// Process memories into stories
app.post('/api/stories/process', verifyFirebaseToken, ensureUserScope, async (req, res) => {
    try {
        const { conversationId } = req.body;
        const result = await ragService.processMemoriesIntoStories(req.userId, conversationId);
        res.json(result);
    } catch (error) {
        console.error('Error processing memories into stories:', error);
        res.status(500).json({ 
            error: 'Failed to process memories into stories',
            details: process.env.NODE_ENV === 'development' ? error.message : undefined
        });
    }
});

// Search stories using semantic search
app.post('/api/stories/search', verifyFirebaseToken, ensureUserScope, async (req, res) => {
    try {
        const { query, limit = 10, threshold = 0.7, people = [], places = [], events = [] } = req.body;
        
        if (!query || typeof query !== 'string') {
            return res.status(400).json({ error: 'Query is required and must be a string' });
        }

        const options = { limit, threshold, people, places, events };
        const result = await ragService.searchStories(req.userId, query, options);
        res.json(result);
    } catch (error) {
        console.error('Error searching stories:', error);
        res.status(500).json({ 
            error: 'Failed to search stories',
            details: process.env.NODE_ENV === 'development' ? error.message : undefined
        });
    }
});

// Get relevant stories for agent context
app.post('/api/stories/relevant', verifyFirebaseToken, ensureUserScope, async (req, res) => {
    try {
        const { context, maxStories = 5 } = req.body;
        
        if (!context || typeof context !== 'string') {
            return res.status(400).json({ error: 'Context is required and must be a string' });
        }

        const result = await ragService.getRelevantStories(req.userId, context, maxStories);
        res.json(result);
    } catch (error) {
        console.error('Error getting relevant stories:', error);
        res.status(500).json({ 
            error: 'Failed to get relevant stories',
            details: process.env.NODE_ENV === 'development' ? error.message : undefined
        });
    }
});

// Get user stories with pagination
app.get('/api/stories', verifyFirebaseToken, ensureUserScope, async (req, res) => {
    try {
        const { limit = 20, offset = 0, sortBy = 'created_at', sortOrder = 'DESC' } = req.query;
        const options = { 
            limit: parseInt(limit), 
            offset: parseInt(offset), 
            sortBy, 
            sortOrder 
        };
        
        const result = await ragService.getUserStories(req.userId, options);
        res.json(result);
    } catch (error) {
        console.error('Error getting user stories:', error);
        res.status(500).json({ 
            error: 'Failed to get user stories',
            details: process.env.NODE_ENV === 'development' ? error.message : undefined
        });
    }
});

// Get story statistics
app.get('/api/stories/stats', verifyFirebaseToken, ensureUserScope, async (req, res) => {
    try {
        const result = await ragService.getStoryStats(req.userId);
        res.json(result);
    } catch (error) {
        console.error('Error getting story stats:', error);
        res.status(500).json({ 
            error: 'Failed to get story statistics',
            details: process.env.NODE_ENV === 'development' ? error.message : undefined
        });
    }
});

// Health check endpoint
app.get('/api/health', async (req, res) => {
    const dbPing = typeof db.ping === 'function' ? await db.ping() : { ok: undefined, configured: !!process.env.DATABASE_URL };
    const encKey = process.env.ENCRYPTION_KEY || '';
    const encValid = !!encKey && encKey.length === 64;
    res.json({ 
        status: 'healthy', 
        timestamp: new Date().toISOString(),
        anthropicConfigured: !!process.env.ANTHROPIC_API_KEY,
        openaiConfigured: !!process.env.OPENAI_API_KEY,
        database: {
            configured: dbPing.configured,
            ok: dbPing.ok,
            error: dbPing.error
        },
        encryption: {
            configured: !!encKey,
            length: encKey.length,
            validFormat: encValid
        }
    });
});

// Serve the main app
app.get('/', (req, res) => {
    res.sendFile(path.join(__dirname, 'index.html'));
});

// Error handling middleware
app.use((error, req, res, next) => {
    console.error('Server Error:', error);
    res.status(500).json({ 
        error: 'Internal server error',
        details: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
});

// 404 handler
app.use((req, res) => {
    res.status(404).json({ error: 'Endpoint not found' });
});

// Function warming scheduler (every 10 minutes)
function startWarmingScheduler() {
    const warmInterval = 10 * 60 * 1000; // 10 minutes
    setInterval(async () => {
        try {
            const response = await fetch(`http://localhost:${process.env.PORT || 3000}/warm`);
            const data = await response.json();
            console.log(`ğŸ”¥ Warming ping: ${data.status}`);
        } catch (error) {
            console.log(`âš ï¸ Warming failed: ${error.message}`);
        }
    }, warmInterval);
    
    // Initial warm after 30 seconds
    setTimeout(async () => {
        try {
            const response = await fetch(`http://localhost:${process.env.PORT || 3000}/warm`);
            const data = await response.json();
            console.log(`ğŸ”¥ Initial warming: ${data.status}`);
        } catch (error) {
            console.log(`âš ï¸ Initial warming failed: ${error.message}`);
        }
    }, 30000);
}

// Start the server only when executed directly, not when imported by tests
if (require.main === module) {
    app.listen(PORT, () => {
        console.log(`ğŸš€ Story Collection server running on port ${PORT}`);
        console.log(`ğŸ“ Environment: ${process.env.NODE_ENV || 'development'}`);
        console.log(`ğŸ¤– Anthropic API: ${process.env.ANTHROPIC_API_KEY ? 'âœ… Configured' : 'âŒ Missing'}`);
        console.log(`ğŸŒ Access at: http://localhost:${PORT}`);
        
        // Start warming scheduler in production
        if (process.env.NODE_ENV === 'production') {
            startWarmingScheduler();
            console.log(`ğŸ”¥ Function warming enabled (10min intervals)`);
        }
    });
}

module.exports = app;
